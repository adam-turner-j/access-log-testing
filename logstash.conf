input {
    s3 {
        bucket => "${source_bucket}"
        region => "${source_region}"
        exclude_pattern => "^(?!(?:(?:elb_access_logs\/(?:DATA-Act-Broker-API|broker-files-prod|usaspending-api-prod-elb|usaspending-files-prod))\/.*us-gov-west-1\/(?:20(?:19|[2-9][0-9])|2[1-9][0-9][0-9]|[3-9][0-9][0-9][0-9]).*)).*$"
        watch_for_new_files => false
    }
}

filter {
  grok {
    match => {
      "message" => [
        # ELB access logs
        "%{TIMESTAMP_ISO8601:timestamp} %{GREEDYDATA} %{IP:client_ip}\:%{INT} %{IP}\:%{INT} %{GREEDYDATA}",
        # CloudFront access logs
        "(?<timestamp>%{YEAR}-%{MONTHNUM}-%{MONTHDAY}%{SPACE}%{TIME})%{SPACE}%{DATA}%{SPACE}%{INT}%{SPACE}%{IP:client_ip}%{GREEDYDATA}",
        # DataLab cdn logs
        "%{IP:client_ip} - - \[%{DATA:timestamp}\] \"%{WORD} %{DATA} HTTP/%{NUMBER}\" %{INT} %{INT} \"%{DATA}\" \"%{DATA}\" \"%{DATA}\" \"%{DATA}\""
      ]
    }
  }
  mutate {
    gsub => [
      # replace all whitespace characters or multiple adjacent whitespace characters with one space
      "timestamp", "\s+", " "
    ]
  }
  date {
    match => ["timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss", "dd/MMM/yyyy:HH:mm:ss Z"]
    target => "@timestamp"
  }
  geoip {
    source => "client_ip"
  }
  if [geoip][country_name] == "United States" {
    drop {}
  }
  mutate {
    remove_field => [ "timestamp" ]
    gsub => [
      "[@metadata][s3][key]", "(?:.(?!\/))+$", "/"
    ]
  }
}

output {
  s3 {
    bucket => "${dest_bucket}"
    prefix => "%{[@metadata][s3][key]}"
    region => "${dest_region}"
    codec => json_lines
    size_file => 52428800
    rotation_strategy => "size"
  }
}
